{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consuming data using Kafka and Visualise (20%)\n",
    "In this task, we will implement an Apache Kafka consumer to consume the data from Part 2.  \n",
    "  \n",
    "Important:   \n",
    "-\tIn this part, Kafka consumers are used to consume the streaming data published from task 2.8.  \n",
    "-\tThis visualisation part doesn’t require parallel processing, so please do not use Spark. It’s OK to use Pandas or any Python library to do simple calculations for the visualisation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kafka-python pandas matplotlib seaborn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (Basic plot) Plot a diagram to show data from 6a (i.e. every 15 seconds, plot the total number of revenues for each type of order.) You are free to choose the type of plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Kafka Configurations\n",
    "kafka_bootstrap_servers = \"kafka:9092\"\n",
    "kafka_topic_6a = \"time_windowed_revenue_topic\"\n",
    "\n",
    "# Initialize Kafka Consumer with a timeout (10 seconds)\n",
    "consumer = KafkaConsumer(\n",
    "    kafka_topic_6a,\n",
    "    bootstrap_servers=kafka_bootstrap_servers,\n",
    "    auto_offset_reset=\"earliest\",\n",
    "    enable_auto_commit=True,\n",
    "    value_deserializer=lambda x: json.loads(x.decode(\"utf-8\")),\n",
    "    consumer_timeout_ms=10000  # Timeout after 10 seconds if no data\n",
    ")\n",
    "\n",
    "# Data Storage\n",
    "data_list = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Consume messages from Kafka\n",
    "for message in consumer:\n",
    "    data = message.value\n",
    "    time_window_start = data[\"time_window\"][\"start\"]\n",
    "    order_type = data[\"type_of_order\"]\n",
    "    revenue = data[\"total_revenue\"]\n",
    "\n",
    "    # Store data in list\n",
    "    data_list.append({\n",
    "        \"time_window\": time_window_start,\n",
    "        \"type_of_order\": order_type,\n",
    "        \"total_revenue\": revenue\n",
    "    })\n",
    "\n",
    "    # Stop after collecting enough data\n",
    "    if len(data_list) > 50 or (time.time() - start_time) > 15:  # Max 15 seconds\n",
    "        break\n",
    "\n",
    "# Close consumer\n",
    "consumer.close()\n",
    "\n",
    "# Print status\n",
    "print(f\"Collected {len(data_list)} messages.\")\n",
    "\n",
    "# If no data, exit\n",
    "if not data_list:\n",
    "    print(\"No data received from Kafka.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Convert to Pandas DataFrame\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mdata_list\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Convert time_window to datetime for plotting\u001b[39;00m\n\u001b[1;32m      6\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_window\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_window\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_list' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Convert to Pandas DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Convert time_window to datetime for plotting\n",
    "df[\"time_window\"] = pd.to_datetime(df[\"time_window\"])\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x=\"time_window\", y=\"total_revenue\", hue=\"type_of_order\", marker=\"o\")\n",
    "\n",
    "# Formatting\n",
    "plt.xlabel(\"Time Window (Every 15s)\")\n",
    "plt.ylabel(\"Total Revenue\")\n",
    "plt.title(\"Total Revenue per Order Type (Every 15 Seconds)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Order Type\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\t(Advanced plot) Plot a choropleth or bubble map to visualise data from 6b (restaurant’s suburb-based order count for <=15 and >15 minutes; you may use different colors or subplots.).  \n",
    "Choropleth: https://python-graph-gallery.com/choropleth-map/  \n",
    "Bubble Map: https://python-graph-gallery.com/bubble-map/  \n",
    "Note: Both plots shall be real-time plots, which will be updated if new streaming data comes in from part 2. For the advanced plot, if you need additional data for the plots, you can add them in part 2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data from the saved parquet file\n",
    "delivery_time_aggregation_df = pd.read_parquet(\"parquet/delivery_time_aggregation\")\n",
    "\n",
    "# Load the map data (Assuming we have a shapefile with suburb boundaries)\n",
    "suburb_map = gpd.read_file(\"suburb_boundaries.shp\")\n",
    "\n",
    "# Aggregate counts per suburb\n",
    "suburb_aggregated = delivery_time_aggregation_df.groupby(\"restaurant_suburb\").sum().reset_index()\n",
    "\n",
    "# Merge with the geographical data\n",
    "merged = suburb_map.merge(suburb_aggregated, left_on=\"suburb_name\", right_on=\"restaurant_suburb\")\n",
    "\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "# Plot orders <= 15 minutes\n",
    "merged.plot(column=\"count_under_15\", cmap=\"Blues\", linewidth=0.8, edgecolor=\"black\", legend=True, ax=ax[0])\n",
    "ax[0].set_title(\"Orders Delivered in ≤15 Minutes\")\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "# Plot orders > 15 minutes\n",
    "merged.plot(column=\"count_over_15\", cmap=\"Reds\", linewidth=0.8, edgecolor=\"black\", legend=True, ax=ax[1])\n",
    "ax[1].set_title(\"Orders Delivered in >15 Minutes\")\n",
    "ax[1].set_axis_off()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
